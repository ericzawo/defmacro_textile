---
layout: post
title: Software engineering, lessons learned
wip: true
---

h1. {{ page.title }}

p(meta). 04 Apr 2013

Over the course of building "RethinkDB":http://www.rethinkdb.com we learned many software engineering lessons. Most of these lessons feel like rediscovered platitudes, but we still managed to mess them up. Considering how many teams are struggling with shipping software, I thought these lessons are worth repeating.

h3. Instill shared culture

Sooner or later you'll discover you've hired engineers on your team that have very different philosophies on how software should be built. Say, a C programmer, and a C++ programmer. The former will want the codebase to look like the Linux kernel. The latter will want it to look like the boost MPL library. What's a well-meaning engineering manager to do?

I've tried all possible ways of addressing the ensuing social issues (including doing nothing), and found that there is only one approach that works. Always, always, always fight to cultivate and enforce shared culture. It can be unpleasant early on, but it's the only way I know of to build a team that's both happy _and_ productive.

h3. Code review everything

The absolute best way to instill shared culture is to code review every line of code before it ever goes into mainline. (Why _every_ line of code? Because code reviews don't stick if you do them selectively. Take my word for it -- some rules need to be absolute.)

Here's how we do it. By default, the reviewer is always right, and the author must fix every defect (we ask the reviewers to be tough, but reasonable). If the author _really_ disagrees with the reviewer, they can appeal to a tech lead. The tech lead's decision is final, and cannot be appealed. You can find a different way to do it, but we found this to be a pretty good system.

Code review is like exercise. Painful at the beginning, and any given session might feel like a waste of time. But over the lifetime of a project, it makes _all_ the difference. Always code review _every single commit_. No ifs, no buts, no exceptions.

h3. It's the product, stupid

Ability to build great software and ability to build great products are two completely othogonal skills, and aptitude for the former does not in any way imply aptitude for the latter. It's best to learn early that software companies aren't about building great software. They're about building great products. You have to start with the product, and let great software be a means to an end.

Make sure every engineer on the team respects this principle and fire "smug weenies":http://c2.com/cgi/wiki?SmugLispWeenie at the first sign of trouble. Whenever possible, have people that understand _products_ run the show.

h3. Fight complexity with all you've got

Linear increases in complexity cause superlinear increases in amount of work to be done. Be careless about complexity, and before you know it your development process will crawl to a halt.

Complexity increases the surface area of your project. In software engineering, large surface area is death. Fight, fight, fight complexity with everything you've got. If you can avoid adding new functionality, fight like hell to keep it out. If you lose that fight, see if you can get 80% of the functionality with 20% of the work. Usually, you can. Fight like hell to do it that way. If you lose _this_ fight, either you've hit the one case in a thousand where complexity is warranted, or, more likely, you should have fought harder.

Less is more. Avoid grand desings. Keep the codebase as small as possible.

h3. Pick abstractions carefully

Pick the simplest, most concrete possible implementation that solves the customer's problem. Avoid big abstractions -- functions are better than "lenses":http://hackage.haskell.org/package/lens 99.999% of the time. Use simpler language features whenever possible -- an if statement is better than a template specialization. Great abstractions feel both simultaneously very abstract in that you can do an enormous number of different things with them, and very concrete in that doing any specific thing is easy and simple to understand. That's why functions and pipes are better abstractions than monads and "arrows":http://www.haskell.org/arrows/.

Avoid grand beautiful designs -- they're never as grand and as beautiful as you've envisioned them.

h3. Sprints, deadlines, and estimates

I've observed the following two aspects of software development so many times, I've learned to accept them as axioms:

1. Humans are terrible at time estimation for anything longer than 2-4 days of work.
2. Lack of deadlines is a sure road to complex software with bad, overengineered abstractions.

Despite smelling like a fad, sprints are a surprisingly good solution to the seemingly impossible scheduling problem. Break up all work into no more than 2-4 day chunks (usually represented as issues in a tracker). Assign these issues to people, and group them into sprints of one to two weeks. Then work like hell together to get everything in a sprint done on time.

It's strange, but with the right people it works really, really well. (Some people can't work in this environment -- in that case your best option is to kindly ask them to switch employers).

h3. Overallocate resources

Here's a resource allocation algorithm:

# Pick the most important priority.
# Allocate as many people to it as the task can handle. Don't be afraid of overallocating, be terrified of underallocating.
# With the remaining people go to step 1.

Overparallelization is death.

h3. Treat big projects with care

Not all projects can be broken up in a way that allows fitting them into a single sprint. Some projects are just too big. You have to treat these projects differently.

Firstly, fight as hard as you can to _not_ build big projects. Break them up into smaller ones, find a different approach, don't build the feature in the first place, do everything you have to do to keep them out.

If you've done all you can and still _must_ build a big project, build the absolute most minimal prototype possible. Cut corners, dumb it down, do all you can to decrease the scope. Make sure there is a single engineer in charge of the project, and put structure around it. Do a peer review of the initial design. Then set up deliverable milestones, and do peer reviews for each milestone. Once the project is feature complete in the shortest possible amount of time, assign improvements as part of the standard sprint schedule.

Keep the number of concurrent big projects to absolute minimum. One big project per team of about eight - ten engineers is a good rule of thumb.

h3. Never do large rewrites

It kills you.

h3. Test less code more often

We've all heard the TDD mantra -- write tests first, always keep them green, maximize code coverage. Empirically, I've found that this testing philosophy produces very binary results. You get one of two outcomes:

1. High code coverage with mostly failing, bitrotted tests.
2. Relatively low code coverage with always green tests.

When forced to choose (and you _will_ be forced) between these two outcomes, always pick the second one.

The temptation of high code coverage results in long tests that aren't possible to run after every commit. If you can't run tests after every commit, it becomes increasingly more impractical to run every test before committing a change to mainline. If you can't run every test before committing to mainline, your tests _will_ bitrot.

Instead, have fewer tests that everyone runs after every commit. Use a tool like "Travis CI":https://travis-ci.org/, and replace thousands of bitrotted unit tests with a few carefully selected integration tests.

Fewer tests that are always green _always_ beat more tests that are bitrotted, and unfortunately it looks like every project is forced to choose between these two options.